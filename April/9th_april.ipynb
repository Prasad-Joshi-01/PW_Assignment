{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e1fd0-668a-4e54-90b0-2af237a35d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes theorem?\n",
    "Ans:\n",
    "Bayes theorem is a mathematical formula that describes the probability of an event, based on prior knowledge or information.\n",
    "It was developed by Reverend Thomas Bayes, an 18th-century statistician and theologian.\n",
    "\n",
    "The formula is:\n",
    "\n",
    "P(A|B) = P(B|A) x P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A occurring\n",
    "P(B) is the prior probability of event B occurring\n",
    "Bayes theorem is often used in machine learning and data analysis to update predictions based on new information. \n",
    "It is also used in a wide range of applications, from medical diagnosis to spam filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee455-626e-40d0-a0d3-1bbe2976515a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064ce35-9d9a-47eb-8781-a05e59377d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the formula for Bayes theorem?\n",
    "Ans:\n",
    "The formula for Bayes theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) x P(A) / P(B)\n",
    "\n",
    "where:\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A occurring\n",
    "P(B) is the prior probability of event B occurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee470f22-8816-4672-8f24-b22a82062cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec817568-4a8b-4830-8e32-87d07a236451",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How is Bayes theorem used in practice?\n",
    "Ans:\n",
    "Bayes theorem is used in a wide range of fields and applications, including:\n",
    "\n",
    "1.Medical diagnosis: Bayes theorem can be used to calculate the probability that a patient has a particular disease, given their symptoms and other relevant information.\n",
    "2.Spam filtering: Bayes theorem is used to classify emails as spam or not spam based on their content and other features.\n",
    "3.Search engines: Bayes theorem can be used to rank search results based on their relevance to a users query.\n",
    "4.Weather forecasting: Bayes theorem can be used to update weather forecasts based on new data, such as temperature readings and weather patterns.\n",
    "5.Image recognition: Bayes theorem can be used to classify images based on their features, such as colors and shapes.\n",
    "\n",
    "In practice, Bayes theorem is used in combination with other statistical and machine learning techniques to make predictions and decisions based on available data. \n",
    "It can be particularly useful in situations where new information is continually being collected and the probability of an event changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db3b0f-d4d6-44f2-853b-65944de19056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b15adf-18c3-4c98-b1e1-e3bc90b52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between Bayes theorem and conditional probability?\n",
    "Ans:\n",
    "Bayes theorem and conditional probability are closely related concepts.\n",
    "Conditional probability is the probability of an event A occurring given that another event B has occurred, and is denoted as P(A|B).\n",
    "Bayes theorem is a way of calculating conditional probabilities, by reversing the order of the events.\n",
    "\n",
    "Specifically, Bayes theorem states that:\n",
    "\n",
    "P(A|B) = P(B|A) x P(A) / P(B)\n",
    "\n",
    "This formula calculates the probability of event A occurring given that event B has occurred, based on the probability of event B occurring given that event A has occurred,\n",
    "the prior probability of event A occurring, and the prior probability of event B occurring.\n",
    "\n",
    "In essence, Bayes theorem provides a way to update our beliefs about the probability of an event A occurring, given new information provided by event B. \n",
    "It is particularly useful when we have prior knowledge about the probability of A and B occurring, and we want to update that knowledge based on new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ff00d-5e87-4d12-bedf-1d1a91ac3b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f1e75-b3df-41be-9c13-4298a0d6ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "Ans:\n",
    "There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes.\n",
    "\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the data and the problem being solved. \n",
    "Here are some general guidelines:\n",
    "\n",
    "1.Gaussian Naive Bayes: This classifier is used for continuous data that follows a Gaussian distribution, also known as a normal distribution. \n",
    "It assumes that the features are normally distributed and uses mean and variance to determine the likelihood of a particular class.\n",
    "\n",
    "2.Multinomial Naive Bayes: This classifier is used for discrete count data, such as word counts in text classification problems. \n",
    "It assumes that the features are generated from a multinomial distribution and uses the frequency of each feature to determine the likelihood of a particular class.\n",
    "\n",
    "3.Bernoulli Naive Bayes: This classifier is used for binary data, such as presence or absence of a feature in text classification problems.\n",
    "It assumes that each feature is generated from a Bernoulli distribution and uses the presence or absence of each feature to determine the likelihood of a particular class.\n",
    "\n",
    "In practice, it is often a good idea to try all three types of Naive Bayes classifiers and see which one performs best on the specific problem and data at hand. \n",
    "The choice of classifier can also depend on the size and complexity of the data, as well as the availability of prior knowledge about the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433517b2-a390-4fee-ae67-09ad286f81b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7a771-e7a7-4f90-b84b-e25074fad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A      3     3   4    4    3    3    3\n",
    "B      2     2   1    2    2    2    3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "Ans:\n",
    "To use Naive Bayes to classify the new instance with features X1 = 3 and X2 = 4, we need to calculate the likelihood of each class given the feature values.\n",
    "\n",
    "We can use the following formula for Naive Bayes:\n",
    "\n",
    "P(Class | X1, X2) = P(X1, X2 | Class) * P(Class) / P(X1, X2)\n",
    "\n",
    "where P(Class | X1, X2) is the posterior probability of the class given the feature values, P(X1, X2 | Class) is the likelihood of the feature values given the class,\n",
    "P(Class) is the prior probability of the class, and P(X1, X2) is the marginal probability of the feature values.\n",
    "\n",
    "Since we are assuming equal prior probabilities for each class, P(Class) is 0.5 for both classes.\n",
    "\n",
    "To calculate the likelihood of the feature values given each class, we can use the frequencies in the table. \n",
    "For example, the likelihood of Class A given X1 = 3 and X2 = 4 is:\n",
    "\n",
    "P(X1=3, X2=4 | A) = (4/14) * (3/14) = 0.061\n",
    "\n",
    "where 4/14 is the frequency of X1=3 in Class A, 3/14 is the frequency of X2=4 in Class A, and we are assuming independence between the features.\n",
    "\n",
    "We can calculate the likelihood of Class B given X1 = 3 and X2 = 4 in the same way:\n",
    "\n",
    "P(X1=3, X2=4 | B) = (1/10) * (3/10) = 0.03\n",
    "\n",
    "We also need to calculate the marginal probability of the feature values, which is the sum of the likelihoods for each class:\n",
    "\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) + P(X1=3, X2=4 | B) * P(B)\n",
    "= 0.061 * 0.5 + 0.03 * 0.5\n",
    "= 0.0455\n",
    "\n",
    "Finally, we can calculate the posterior probabilities for each class:\n",
    "\n",
    "P(A | X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) / P(X1=3, X2=4)\n",
    "= 0.061 * 0.5 / 0.0455\n",
    "= 0.671\n",
    "\n",
    "P(B | X1=3, X2=4) = P(X1=3, X2=4 | B) * P(B) / P(X1=3, X2=4)\n",
    "= 0.03 * 0.5 / 0.0455\n",
    "= 0.329\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance belongs to Class A, since it has a higher posterior probability of 0.671 compared to Class B posterior probability of 0.329."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
