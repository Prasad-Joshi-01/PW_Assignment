{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f2e83-4d66-4d2d-baeb-1da418555640",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "Ans:\n",
    "Polynomial functions and kernel functions are related in machine learning algorithms in that polynomial functions are often used as the basis for constructing kernel functions.\n",
    "\n",
    "In kernel methods, data is represented in a high-dimensional feature space, where a linear classifier can be used to separate the data into different classes.\n",
    "However, computing the linear classifier in this high-dimensional space can be computationally expensive or even impossible in some cases.\n",
    "\n",
    "Kernel functions are used to address this problem by allowing us to compute the classifier in the original low-dimensional input space, while still effectively working in the high-dimensional feature space.\n",
    "A kernel function is a function that measures the similarity between two data points in the input space, and it can be used to implicitly map the data into the high-dimensional feature space.\n",
    "\n",
    "Polynomial functions can be used as the basis for constructing kernel functions by raising the dot product between two input vectors to a certain power. \n",
    "For example, a quadratic kernel can be constructed by taking the dot product of two vectors and squaring it:\n",
    "\n",
    "K(x, y) = (x · y)²\n",
    "\n",
    "This is equivalent to mapping the input vectors to a higher-dimensional feature space where each feature represents all possible products of two input features up to degree 2. This allows us to capture nonlinear relationships between the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d203e-7630-4c29-be86-1ff323a83de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37cb9e-17e6-4fed-9cbf-a53078e8c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cfc0d38-9eaf-4981-9ab8-27d9943446a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create an SVM classifier with a polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d3761-2759-4c7c-8d3a-d0f4df5657e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "Ans:\n",
    "In Support Vector Regression (SVR), the parameter epsilon controls the width of the epsilon-insensitive tube, \n",
    "which is the region around the regression line where errors are not penalized. \n",
    "The larger the value of epsilon, the wider the tube, and the more tolerant the model is to errors.\n",
    "\n",
    "Increasing the value of epsilon generally leads to an increase in the number of support vectors in SVR.\n",
    "This is because a larger epsilon allows more data points to fall within the epsilon-insensitive tube,\n",
    "and therefore more support vectors are needed to define the regression line that minimizes the error while respecting the width of the tube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0945-70e1-438b-9418-4e614edb3754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79ef64-5b22-4dc2-b98a-91b03a75b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "Ans:\n",
    "The choice of kernel function, C parameter, epsilon parameter, and gamma parameter can have a significant impact on the performance of Support Vector Regression (SVR). \n",
    "Heres how each parameter works and how it affects the performance of SVR:\n",
    "\n",
    "Kernel function: The kernel function maps the input data to a higher-dimensional space where it may be easier to separate the data points.\n",
    "Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid. \n",
    "The choice of kernel function depends on the characteristics of the data and the complexity of the decision boundary.\n",
    "For example, a linear kernel may work well for linearly separable data, while an RBF kernel may work better for non-linear data. \n",
    "In general, the RBF kernel is the most commonly used kernel function for SVR.\n",
    "\n",
    "C parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error.\n",
    "A smaller value of C will result in a wider margin, which may lead to more errors on the training set but better generalization to new data.\n",
    "A larger value of C will result in a narrower margin, which may lead to fewer errors on the training set but worse generalization to new data. \n",
    "In general, a good starting value for C is 1.0, and it can be adjusted based on the characteristics of the data.\n",
    "\n",
    "Epsilon parameter: The epsilon parameter controls the width of the epsilon-insensitive tube around the regression line. \n",
    "A larger value of epsilon allows more data points to fall within the tube, which may lead to more support vectors but a more flexible model.\n",
    "A smaller value of epsilon results in a stricter model that may be more prone to overfitting. A good starting value for epsilon is 0.1,\n",
    "and it can be adjusted based on the characteristics of the data.\n",
    "\n",
    "Gamma parameter: The gamma parameter controls the shape of the decision boundary.\n",
    "A smaller value of gamma results in a wider and more generalized decision boundary, while a larger value of gamma results in a narrower and \n",
    "more precise decision boundary.\n",
    "In general, a good starting value for gamma is 0.1, and it can be adjusted based on the characteristics of the data.\n",
    "\n",
    "Here are some examples of when you might want to increase or decrease the values of these parameters:\n",
    "\n",
    "Kernel function: If the data is linearly separable, a linear kernel may work well, but if the data is non-linear, an RBF or polynomial kernel may be more appropriate.\n",
    "C parameter: If the goal is to achieve a lower training error, a larger value of C may be used, but if the goal is to minimize the testing error and\n",
    "prevent overfitting, a smaller value of C may be used.\n",
    "Epsilon parameter: If the data is noisy or has outliers, a larger value of epsilon may be used to make the model more tolerant to errors, but if the data is clean,\n",
    "a smaller value of epsilon may be used for a stricter model.\n",
    "Gamma parameter: If the data is complex and non-linear, a larger value of gamma may be used to create a more precise decision boundary, but if the data is simpler,\n",
    "a smaller value of gamma may be used for a more generalized decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcaa7b-88b6-49af-99ab-d90f02bf3a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb3152-038f-40a1-9003-00b3c0489bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6673fd38-2c6b-4d4e-afa3-e1fbb7b9fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.375 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=10, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=100, kernel=rbf;, score=0.542 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=100, kernel=rbf;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END .......C=100, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .......C=100, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=100, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .......C=100, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=100, kernel=rbf;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "tuned_clf = SVC(**grid.best_params_)\n",
    "tuned_clf.fit(data.data, data.target)\n",
    "\n",
    "import pickle\n",
    "file = open('SVC_classifier.pkl','wb')\n",
    "pickle.dump(tuned_clf,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36467f1a-19ff-48de-99bd-45288787788d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
